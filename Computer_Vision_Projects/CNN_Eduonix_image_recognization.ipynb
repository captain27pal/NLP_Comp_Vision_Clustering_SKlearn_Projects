{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-05a258e72fe3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# We can simply import the data from keras.dataset. First import cifar10 and then run the command cifar10.load_data()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcifar10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "##Loading CIFAR10 dataset .as 60000 images devided into 10 common classes. 50k images for train and 10k for testing the performance of the network\n",
    "\n",
    "#The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes,\n",
    "# We can simply import the data from keras.dataset. First import cifar10 and then run the command cifar10.load_data()\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-d49229f96f7d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnp_utils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "import matplotlib\n",
    "from keras.utils import np_utils\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sys version: 3.7.6 (default, Jan  8 2020, 20:23:39) [MSC v.1916 64 bit (AMD64)]\n",
      "matplotlib version: 3.1.3\n",
      "keras version : 2.3.1\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"sys version: {}\".format(sys.version))\n",
    "print('matplotlib version: {}'.format(matplotlib.__version__))\n",
    "print(f\"keras version : {keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train,y_train),(X_test,y_test)=cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data shape :(50000, 32, 32, 3)\n",
      "test data shape: (10000, 32, 32, 3)\n",
      "(32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "##now since we have the dataset, lets explore the data a little bit\n",
    "\n",
    "print(f\"train data shape :{X_train.shape}\")\n",
    "print(f\"test data shape: {X_test.shape}\")\n",
    "print(X_train[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-1c8bb843835d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#lets plot some images. pretty small images. it is dais that human accuracy is about 90 in this dataset. So, if we can achieve an accuraacy higher than that, we will do a pretty good job\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_subplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m330\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#lets plot some images. pretty small images. it is dais that human accuracy is about 90 in this dataset. So, if we can achieve an accuraacy higher than that, we will do a pretty good job\n",
    "\n",
    "f=plt.figure(figsize=(5,5))\n",
    "for i in range(0,9):\n",
    "    f.add_subplot(330+1+i)\n",
    "    img=X_test[i]\n",
    "    plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.00090734 0.00095348 0.00096886]\n",
      "  [0.00066128 0.00070742 0.00069204]\n",
      "  [0.00076894 0.00073818 0.00066128]\n",
      "  ...\n",
      "  [0.00242983 0.00202999 0.0016609 ]\n",
      "  [0.00233756 0.00192234 0.00156863]\n",
      "  [0.00227605 0.00190696 0.00158401]]\n",
      "\n",
      " [[0.00024606 0.00030757 0.00030757]\n",
      "  [0.         0.         0.        ]\n",
      "  [0.00027682 0.00012303 0.        ]\n",
      "  ...\n",
      "  [0.00189158 0.00135333 0.00084583]\n",
      "  [0.00183007 0.00127643 0.00076894]\n",
      "  [0.0018762  0.00133795 0.00087659]]\n",
      "\n",
      " [[0.00038447 0.00036909 0.00032295]\n",
      "  [0.00024606 0.00010765 0.        ]\n",
      "  [0.00075356 0.00041522 0.00012303]\n",
      "  ...\n",
      "  [0.00181469 0.00129181 0.00076894]\n",
      "  [0.00184544 0.00129181 0.00076894]\n",
      "  [0.00167628 0.00112265 0.00064591]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[0.00319877 0.00261438 0.00147636]\n",
      "  [0.00309112 0.00235294 0.00052288]\n",
      "  [0.00304498 0.00247597 0.00039985]\n",
      "  ...\n",
      "  [0.00246059 0.00204537 0.00107651]\n",
      "  [0.00086121 0.00047674 0.00010765]\n",
      "  [0.00081507 0.00052288 0.00030757]]\n",
      "\n",
      " [[0.00276817 0.00213764 0.00147636]\n",
      "  [0.00266052 0.00189158 0.00064591]\n",
      "  [0.00286044 0.00221453 0.00046136]\n",
      "  ...\n",
      "  [0.00282968 0.00227605 0.0014456 ]\n",
      "  [0.00149173 0.00095348 0.00052288]\n",
      "  [0.00127643 0.00081507 0.00052288]]\n",
      "\n",
      " [[0.00272203 0.00221453 0.00178393]\n",
      "  [0.00258362 0.00198385 0.0014456 ]\n",
      "  [0.00275279 0.00218378 0.00133795]\n",
      "  ...\n",
      "  [0.0033218  0.00282968 0.00215302]\n",
      "  [0.00232218 0.00181469 0.00129181]\n",
      "  [0.00189158 0.00141484 0.00110727]]]\n"
     ]
    }
   ],
   "source": [
    "#Lets normalize the data by dividing by 255\n",
    "seed=6\n",
    "np.random.seed(seed)\n",
    "X_train=X_train/255.0\n",
    "X_test=X_test/255.0\n",
    "# X_train=X_train.astype(\"float32\")\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape of label data:\n",
      "(50000, 1)\n",
      "(10000, 1)\n",
      "shape of label dataset after one hot encoding:\n",
      "(10000, 10)\n",
      "(50000, 10)\n",
      "no of classes: 1\n"
     ]
    }
   ],
   "source": [
    "# we will have to do some pre-processing with the label data as its a nulticlass classification(10 class) problem so we are expecting a label shaoe of 10,1\n",
    "# we can do that by deploying one hot encoding\n",
    "print(\"original shape of label data:\")\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)\n",
    "print(\"shape of label dataset after one hot encoding:\")\n",
    "y_test_cat=np_utils.to_categorical(y_test)\n",
    "y_train_cat=np_utils.to_categorical(y_train)\n",
    "print(y_test_cat.shape)\n",
    "print(y_train_cat.shape)\n",
    "print(f\"no of classes: {y_train.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "the image is that of a : frog\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classes=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truc']\n",
    "plt.imshow(X_train[0])\n",
    "print(y_train[0])\n",
    "print(f'the image is that of a : {classes[int(y_train[0])]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##\n",
    " we will be using the All-CNN network published in the 2015 ICLR paper, \"Striving For Simplicity: The All Convolutional Net\". This paper can be found at the following link:\n",
    "\n",
    "https://arxiv.org/pdf/1412.6806.pdf\n",
    "\n",
    "The best model as descibed in the paper\n",
    "\n",
    "* 3×3conv.96ReLU\n",
    "* 3×3conv.96ReLU\n",
    "* 3*3 maxpooling stride 2\n",
    "*3×3conv.192ReLU\n",
    "*3×3conv.192ReLU\n",
    "*3×3max-pooling stride2\n",
    "*3×3conv.192ReLU\n",
    "*1×1conv.192ReLU\n",
    "*1×1conv.10ReLU\n",
    "* global averaging over6×6spatial dimensions\n",
    "\n",
    "* 10 or 100-way softmax\n",
    "\n",
    "##\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,Dropout,Dense,Activation,GlobalAveragePooling2D\n",
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def allcnn(weights=None):\n",
    "\n",
    "    model=Sequential()\n",
    "\n",
    "    model.add(Conv2D(96,(3, 3), padding='same', input_shape=(32,32,3)))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96,(3,3), padding = 'same', ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(96,(3,3), padding = 'same',strides = (2,2) ))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(192,(3,3), padding = 'same', ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192,(3,3), padding = 'same', ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192,(3,3), padding = 'same',strides = (2,2) ))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Conv2D(192,(3,3), padding = 'same', ))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(192,(1,1),padding='valid'))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Conv2D(10,(1,1),padding='valid'))\n",
    "    #addding  global averAGE pooling with softmax\n",
    "\n",
    "    model.add(GlobalAveragePooling2D())\n",
    "    model.add(Activation('softmax'))\n",
    "    #We will use weights from a pre trained model\n",
    "    if weights:\n",
    "        model.load_weights(weights)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "learning_rate=0.01\n",
    "weight_decay=1e-6\n",
    "momentum=0.9\n",
    "\n",
    "model=allcnn()\n",
    "\n",
    "#compiling the model\n",
    "sgd=SGD(lr=learning_rate, decay = weight_decay, momentum = momentum ,    nesterov = True)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics  = ['accuracy'] )\n",
    "\n",
    "# print the model architecture\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "Epoch 1/350\n",
      "22912/50000 [============>.................] - ETA: 27:43 - loss: 2.0926 - accuracy: 0.2066"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-42-c03cbfd27a64>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Lets fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# (X_train,y_train),(X_test,y_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m32\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1239\u001b[1;33m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[0;32m   1240\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[1;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[0;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3740\u001b[1;33m     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3742\u001b[0m     \u001b[1;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1080\u001b[0m     \"\"\"\n\u001b[1;32m-> 1081\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1082\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1083\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[0;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[1;32m-> 1121\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1122\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1123\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Now other parameters\n",
    "epochs=350\n",
    "batch_size=32\n",
    "#Lets fit the model\n",
    "# (X_train,y_train),(X_test,y_test)\n",
    "model.fit(X_train,y_train, validation_data=(X_test, y_test), epochs=epochs, batch_size=32, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since this is a very large model and it will take 100 hours or more to train on our CPU, The best way is to train the model on GPU, which will drastically cut down the training time.\n",
    "# The best we can do is to use a pre-trained model\n",
    "# Search on google for pre-trained model or weights for CIFAR10, ALl-CNN-3 model and use them for our model to make predictions\n",
    "# we will be using the weights from the git hub repository: https://github.com/PAN001/All-CNN\n",
    "# the file with all the weights is: https://github.com/PAN001/All-CNN/blob/master/all_cnn_weights_0.9088_0.4994.hdf5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\WINDOWS\\system32\n"
     ]
    }
   ],
   "source": [
    "#Checking the working directory. the weights file downloaded from github has been stored there\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 32, 32, 96)        2688      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 96)        83040     \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 32, 32, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 16, 16, 96)        83040     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 16, 16, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 16, 16, 192)       166080    \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 192)       331968    \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 16, 16, 192)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 8, 8, 192)         331968    \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 8, 8, 192)         37056     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 8, 8, 192)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_18 (Conv2D)           (None, 8, 8, 10)          1930      \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_2 ( (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 1,369,738\n",
      "Trainable params: 1,369,738\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "10000/10000 [==============================] - 114s 11ms/step\n"
     ]
    }
   ],
   "source": [
    "#hyperparameters\n",
    "# learning_rate=0.01\n",
    "# weight_decay=1e-6\n",
    "# momentum=0.9\n",
    "# Now since we have the weights with us, we do not need the training parameters. Instead of fitting the model we will test the model.\n",
    "weights='all_cnn_weights_0.9088_0.4994.hdf5'\n",
    "\n",
    "model=allcnn(weights)\n",
    "\n",
    "#compiling the model\n",
    "sgd=SGD(lr=learning_rate, decay = weight_decay, momentum = momentum ,    nesterov = True)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=sgd, metrics  = ['accuracy'] )\n",
    "\n",
    "# print the model architecture\n",
    "print(model.summary())\n",
    "\n",
    "# NOW lets test the model and evaluate it on our test data\n",
    "\n",
    "scores=model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10010000318288803\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        list\n",
       "\u001b[1;31mString form:\u001b[0m [4.725852056884766, 0.10010000318288803]\n",
       "\u001b[1;31mLength:\u001b[0m      2\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "Built-in mutable sequence.\n",
       "\n",
       "If no argument is given, the constructor creates a new empty list.\n",
       "The argument must be an iterable if specified.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "type(scores)\n",
    "print(scores[1])\n",
    "scores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truc'}\n"
     ]
    }
   ],
   "source": [
    "classes=range(0,10)\n",
    "\n",
    "names=['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truc']\n",
    "\n",
    "class_labels=dict(zip(classes,names))\n",
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6]\n",
      " [5]\n",
      " [4]\n",
      " [9]\n",
      " [4]\n",
      " [7]\n",
      " [9]\n",
      " [9]\n",
      " [4]\n",
      " [5]\n",
      " [6]] the image is that of a : ship\n"
     ]
    }
   ],
   "source": [
    "batch=X_test[9900:9905]\n",
    "labels=y_test[501:512]\n",
    "\n",
    "print(labels,end=\" \")\n",
    "print(\"the image is that of a : {}\".format(class_labels[int(y_test[1])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "[8 0 1 6 0]\n"
     ]
    }
   ],
   "source": [
    "predictions=model.predict(batch)\n",
    "print(predictions)\n",
    "# this will actually give out the softmax output, which is the probabilities for each class\n",
    "class_results=np.argmax(predictions,axis=-1)\n",
    "print(class_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d1a4389e48>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "plt.imshow(X_test[9904])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'airplane', 1: 'automobile', 2: 'bird', 3: 'cat', 4: 'deer', 5: 'dog', 6: 'frog', 7: 'horse', 8: 'ship', 9: 'truc'}\n"
     ]
    }
   ],
   "source": [
    "print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
